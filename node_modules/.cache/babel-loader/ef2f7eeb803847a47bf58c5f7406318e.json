{"ast":null,"code":"var _jsxFileName = \"/home/oz/Desktop/git/task-app-front/src/components/VoiceRecognition/VoiceRecognition.js\";\nimport React from 'react';\nconst speechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\nconst recognition = new speechRecognition();\nrecognition.continous = true;\nrecognition.lang = 'en-US';\nrecognition.start();\n\nclass VoiceRecognition extends React.Component {\n  constructor() {\n    super();\n\n    this.toggleListen = () => {\n      this.setState({\n        listening: !this.state.listening\n      }, this.handleListen);\n    };\n\n    this.handleListen = () => {\n      if (this.state.listening) recognition.start();\n      let finalTranscript = '';\n\n      recognition.onresult = event => {\n        let interimTranscript = '';\n\n        for (let i = event.resultIndex; i < event.result.length; i++) {\n          const transcript = event.results[i][0].transcript;\n          if (event.result[i].isFinal) finalTranscript += transcript + \"\";else interimTranscript += transcript;\n        }\n\n        document.getElementById('interim').innerHTML = interimTranscript;\n        document.getElementById('final').innerHTML = finalTranscript;\n      };\n    };\n\n    this.state = {\n      count: 0,\n      setCount: 0,\n      listening: false\n    };\n  }\n\n  // componentDidMount() {\n  // \tthis.voiceCommands();\n  // }\n  // voiceCommands = () => {\n  // \tconsole.log('hi there')\n  // \t//On start\n  // \trecognition.onstart = () => {\n  // \t\tconsole.log('Voice is active')\n  // \t}\n  // \t// Do something with result\n  // \trecognition.onresult = (e) => {\n  // \t\tlet current = e.rsultIndex\n  // \t\tlet transcript = e.result[current][0].transcript\n  // \t\tconsole.log(transcript)\n  // \t}\n  // }\n  render() {\n    return /*#__PURE__*/React.createElement(\"div\", {\n      style: container,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 67,\n        columnNumber: 4\n      }\n    }, /*#__PURE__*/React.createElement(\"button\", {\n      id: \"microphone-btn\",\n      style: button,\n      onClick: this.toggleListen,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 68,\n        columnNumber: 5\n      }\n    }), /*#__PURE__*/React.createElement(\"div\", {\n      id: \"interim\",\n      style: final,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 69,\n        columnNumber: 5\n      }\n    }), /*#__PURE__*/React.createElement(\"div\", {\n      id: \"final\",\n      style: final,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 70,\n        columnNumber: 6\n      }\n    }));\n  }\n\n}\n\nexport default VoiceRecognition;","map":{"version":3,"sources":["/home/oz/Desktop/git/task-app-front/src/components/VoiceRecognition/VoiceRecognition.js"],"names":["React","speechRecognition","window","webkitSpeechRecognition","recognition","continous","lang","start","VoiceRecognition","Component","constructor","toggleListen","setState","listening","state","handleListen","finalTranscript","onresult","event","interimTranscript","i","resultIndex","result","length","transcript","results","isFinal","document","getElementById","innerHTML","count","setCount","render","container","button","final"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AAEA,MAAMC,iBAAiB,GAAGC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBAA7D;AAEA,MAAMC,WAAW,GAAG,IAAIH,iBAAJ,EAApB;AAEAG,WAAW,CAACC,SAAZ,GAAwB,IAAxB;AACAD,WAAW,CAACE,IAAZ,GAAmB,OAAnB;AACAF,WAAW,CAACG,KAAZ;;AAEA,MAAMC,gBAAN,SAA+BR,KAAK,CAACS,SAArC,CAA+C;AAC9CC,EAAAA,WAAW,GAAG;AACb;;AADa,SASdC,YATc,GASC,MAAM;AACpB,WAAKC,QAAL,CAAc;AAACC,QAAAA,SAAS,EAAE,CAAC,KAAKC,KAAL,CAAWD;AAAxB,OAAd,EAAkD,KAAKE,YAAvD;AACA,KAXa;;AAAA,SAadA,YAbc,GAaC,MAAM;AACpB,UAAG,KAAKD,KAAL,CAAWD,SAAd,EAAyBT,WAAW,CAACG,KAAZ;AAEzB,UAAIS,eAAe,GAAE,EAArB;;AACAZ,MAAAA,WAAW,CAACa,QAAZ,GAAuBC,KAAK,IAAI;AAC/B,YAAIC,iBAAiB,GAAE,EAAvB;;AAEA,aAAK,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAnB,EAAgCD,CAAC,GAAGF,KAAK,CAACI,MAAN,CAAaC,MAAjD,EAAyDH,CAAC,EAA1D,EACA;AACC,gBAAMI,UAAU,GAAGN,KAAK,CAACO,OAAN,CAAcL,CAAd,EAAiB,CAAjB,EAAoBI,UAAvC;AACA,cAAGN,KAAK,CAACI,MAAN,CAAaF,CAAb,EAAgBM,OAAnB,EAA4BV,eAAe,IAAGQ,UAAU,GAAG,EAA/B,CAA5B,KACKL,iBAAiB,IAAGK,UAApB;AACL;;AAEDG,QAAAA,QAAQ,CAACC,cAAT,CAAwB,SAAxB,EAAmCC,SAAnC,GAA+CV,iBAA/C;AACAQ,QAAAA,QAAQ,CAACC,cAAT,CAAwB,OAAxB,EAAiCC,SAAjC,GAA6Cb,eAA7C;AACA,OAZD;AAaA,KA9Ba;;AAEb,SAAKF,KAAL,GAAa;AACZgB,MAAAA,KAAK,EAAE,CADK;AAEZC,MAAAA,QAAQ,EAAE,CAFE;AAGZlB,MAAAA,SAAS,EAAE;AAHC,KAAb;AAKA;;AAyBD;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEAmB,EAAAA,MAAM,GAAG;AACR,wBACC;AAAK,MAAA,KAAK,EAAEC,SAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC;AAAQ,MAAA,EAAE,EAAG,gBAAb;AAA8B,MAAA,KAAK,EAAGC,MAAtC;AAA8C,MAAA,OAAO,EAAE,KAAKvB,YAA5D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADD,eAEC;AAAK,MAAA,EAAE,EAAG,SAAV;AAAoB,MAAA,KAAK,EAAEwB,KAA3B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAFD,eAGE;AAAK,MAAA,EAAE,EAAC,OAAR;AAAgB,MAAA,KAAK,EAAEA,KAAvB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAHF,CADD;AAOA;;AA9D6C;;AAkE/C,eAAe3B,gBAAf","sourcesContent":["import React from 'react'\n\nconst speechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\n\nconst recognition = new speechRecognition();\n\nrecognition.continous = true\nrecognition.lang = 'en-US'\nrecognition.start()\n\nclass VoiceRecognition extends React.Component {\n\tconstructor() {\n\t\tsuper();\n\t\tthis.state = {\n\t\t\tcount: 0,\n\t\t\tsetCount: 0,\n\t\t\tlistening: false\n\t\t}\t\n\t}\n\t\n\ttoggleListen = () => {\n\t\tthis.setState({listening: !this.state.listening}, this.handleListen)\n\t}\n\n\thandleListen = () => {\n\t\tif(this.state.listening) recognition.start()\n\n\t\tlet finalTranscript =''\n\t\trecognition.onresult = event => {\n\t\t\tlet interimTranscript =''\n\n\t\t\tfor (let i = event.resultIndex; i < event.result.length; i++)\n\t\t\t{\n\t\t\t\tconst transcript = event.results[i][0].transcript\n\t\t\t\tif(event.result[i].isFinal) finalTranscript +=transcript + \"\";\n\t\t\t\telse interimTranscript +=transcript;\n\t\t\t}\n\n\t\t\tdocument.getElementById('interim').innerHTML = interimTranscript\n\t\t\tdocument.getElementById('final').innerHTML = finalTranscript\n\t\t}\n\t}\n\n\t// componentDidMount() {\n\t// \tthis.voiceCommands();\n\t// }\n\n\n\t// voiceCommands = () => {\n\t// \tconsole.log('hi there')\n\t// \t//On start\n\t// \trecognition.onstart = () => {\n\t// \t\tconsole.log('Voice is active')\n\t// \t}\n\n\t// \t// Do something with result\n\t// \trecognition.onresult = (e) => {\n\t// \t\tlet current = e.rsultIndex\n\n\t// \t\tlet transcript = e.result[current][0].transcript\n\t// \t\tconsole.log(transcript)\n\t// \t}\n\t// }\n\n\trender() {\n\t\treturn (\n\t\t\t<div style={container}>\n\t\t\t\t<button id = 'microphone-btn' style ={button} onClick={this.toggleListen} />\n\t\t\t\t<div id = 'interim' style={final}></div>\n\t\t\t\t <div id='final' style={final}></div>\n     \t\t</div>\n\t\t)\n\t}\n}\n\n\nexport default VoiceRecognition;\n\n\n\t"]},"metadata":{},"sourceType":"module"}