{"ast":null,"code":"'use strict';\n\nvar _jsxFileName = \"/home/oz/Desktop/git/task-app-front/src/components/VoiceRecognition/VoiceRecognition.js\";\nimport React, { Component } from 'react';\nimport mic from '../AddTaskForm/mic.png';\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\nconst recognition = new SpeechRecognition();\nrecognition.continous = true;\nrecognition.interimResults = true;\nrecognition.lang = 'en-US';\n\nclass VoiceRecognition extends Component {\n  constructor(props) {\n    super(props);\n\n    this.handleListen = () => {\n      if (this.state.listening) recognition.start();\n      let finalTranscript = '';\n\n      recognition.onresult = event => {\n        let interimTranscript = '';\n\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n          const transcript = event.results[i][0].transcript;\n          if (event.results[i].isFinal) finalTranscript += transcript + ' ';else interimTranscript += transcript;\n        }\n\n        if (document.getElementById('description')) {\n          console.log(document.getElementById('description'));\n          document.getElementById('description').value = finalTranscript;\n          this.props.updateDescriptionInput(finalTranscript);\n        } else {\n          if (finalTranscript === 'no ') {\n            console.log(document.getElementById('cancelEditTask'));\n            document.getElementById('cancelEditTask').click();\n          }\n\n          if (finalTranscript === 'yes ') {\n            document.getElementById('submitEditTask').click();\n          }\n        }\n      };\n    };\n\n    this.state = {\n      listening: false\n    };\n    this.toggleListen = this.toggleListen.bind(this);\n    this.handleListen = this.handleListen.bind(this);\n  }\n\n  toggleListen() {\n    this.setState({\n      listening: !this.state.listening\n    }, this.handleListen);\n  }\n\n  render() {\n    return /*#__PURE__*/React.createElement(\"div\", {\n      style: container,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 63,\n        columnNumber: 4\n      }\n    }, /*#__PURE__*/React.createElement(\"img\", {\n      id: \"microphone-btn\",\n      className: \"pointer grow\",\n      src: mic,\n      width: \"50px\",\n      onClick: this.toggleListen,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 5\n      }\n    }));\n  }\n\n}\n\nexport default VoiceRecognition;\nconst styles = {\n  container: {\n    display: 'flex',\n    flexDirection: 'column',\n    alignItems: 'center',\n    textAlign: 'center'\n  }\n};\nconst {\n  container\n} = styles;","map":{"version":3,"sources":["/home/oz/Desktop/git/task-app-front/src/components/VoiceRecognition/VoiceRecognition.js"],"names":["React","Component","mic","SpeechRecognition","window","webkitSpeechRecognition","recognition","continous","interimResults","lang","VoiceRecognition","constructor","props","handleListen","state","listening","start","finalTranscript","onresult","event","interimTranscript","i","resultIndex","results","length","transcript","isFinal","document","getElementById","console","log","value","updateDescriptionInput","click","toggleListen","bind","setState","render","container","styles","display","flexDirection","alignItems","textAlign"],"mappings":"AAAA;;;AACA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAOC,GAAP,MAAgB,wBAAhB;AAGA,MAAMC,iBAAiB,GAAGC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBAA7D;AACA,MAAMC,WAAW,GAAG,IAAIH,iBAAJ,EAApB;AAEAG,WAAW,CAACC,SAAZ,GAAwB,IAAxB;AACAD,WAAW,CAACE,cAAZ,GAA6B,IAA7B;AACAF,WAAW,CAACG,IAAZ,GAAmB,OAAnB;;AAGA,MAAMC,gBAAN,SAA+BT,SAA/B,CAAyC;AACxCU,EAAAA,WAAW,CAACC,KAAD,EAAQ;AAChB,UAAMA,KAAN;;AADgB,SAenBC,YAfmB,GAeJ,MAAM;AACpB,UAAI,KAAKC,KAAL,CAAWC,SAAf,EAA0BT,WAAW,CAACU,KAAZ;AAEvB,UAAIC,eAAe,GAAG,EAAtB;;AACAX,MAAAA,WAAW,CAACY,QAAZ,GAAuBC,KAAK,IAAI;AAC/B,YAAIC,iBAAiB,GAAG,EAAxB;;AAEA,aAAK,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAnB,EAAgCD,CAAC,GAAGF,KAAK,CAACI,OAAN,CAAcC,MAAlD,EAA0DH,CAAC,EAA3D,EAA+D;AAC9D,gBAAMI,UAAU,GAAGN,KAAK,CAACI,OAAN,CAAcF,CAAd,EAAiB,CAAjB,EAAoBI,UAAvC;AACG,cAAIN,KAAK,CAACI,OAAN,CAAcF,CAAd,EAAiBK,OAArB,EAA8BT,eAAe,IAAIQ,UAAU,GAAG,GAAhC,CAA9B,KACKL,iBAAiB,IAAIK,UAArB;AACR;;AACD,YAAGE,QAAQ,CAACC,cAAT,CAAwB,aAAxB,CAAH,EAA2C;AAC1CC,UAAAA,OAAO,CAACC,GAAR,CAAYH,QAAQ,CAACC,cAAT,CAAwB,aAAxB,CAAZ;AACAD,UAAAA,QAAQ,CAACC,cAAT,CAAwB,aAAxB,EAAuCG,KAAvC,GAA+Cd,eAA/C;AACA,eAAKL,KAAL,CAAWoB,sBAAX,CAAkCf,eAAlC;AACA,SAJD,MAKK;AACJ,cAAGA,eAAe,KAAK,KAAvB,EAA6B;AAC5BY,YAAAA,OAAO,CAACC,GAAR,CAAYH,QAAQ,CAACC,cAAT,CAAwB,gBAAxB,CAAZ;AACAD,YAAAA,QAAQ,CAACC,cAAT,CAAwB,gBAAxB,EAA0CK,KAA1C;AACA;;AACD,cAAGhB,eAAe,KAAK,MAAvB,EAA8B;AAC7BU,YAAAA,QAAQ,CAACC,cAAT,CAAwB,gBAAxB,EAA0CK,KAA1C;AACA;AACD;AAEJ,OAvBE;AAwBH,KA3CkB;;AAEf,SAAKnB,KAAL,GAAa;AACXC,MAAAA,SAAS,EAAE;AADA,KAAb;AAGA,SAAKmB,YAAL,GAAoB,KAAKA,YAAL,CAAkBC,IAAlB,CAAuB,IAAvB,CAApB;AACA,SAAKtB,YAAL,GAAoB,KAAKA,YAAL,CAAkBsB,IAAlB,CAAuB,IAAvB,CAApB;AACD;;AAEFD,EAAAA,YAAY,GAAG;AACb,SAAKE,QAAL,CAAc;AACZrB,MAAAA,SAAS,EAAE,CAAC,KAAKD,KAAL,CAAWC;AADX,KAAd,EAEG,KAAKF,YAFR;AAGD;;AAiCFwB,EAAAA,MAAM,GAAG;AACR,wBACC;AAAK,MAAA,KAAK,EAAEC,SAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACC;AAAK,MAAA,EAAE,EAAG,gBAAV;AACA,MAAA,SAAS,EAAC,cADV;AAEA,MAAA,GAAG,EAAEpC,GAFL;AAGA,MAAA,KAAK,EAAG,MAHR;AAIA,MAAA,OAAO,EAAE,KAAKgC,YAJd;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADD,CADD;AAUA;;AA1DuC;;AA8DzC,eAAexB,gBAAf;AAEA,MAAM6B,MAAM,GAAG;AACbD,EAAAA,SAAS,EAAE;AACTE,IAAAA,OAAO,EAAE,MADA;AAETC,IAAAA,aAAa,EAAE,QAFN;AAGTC,IAAAA,UAAU,EAAE,QAHH;AAITC,IAAAA,SAAS,EAAE;AAJF;AADE,CAAf;AAUA,MAAM;AAAEL,EAAAA;AAAF,IAAgBC,MAAtB","sourcesContent":["'use strict'\nimport React, { Component } from 'react'\nimport mic from '../AddTaskForm/mic.png'\n\n\nconst SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition\nconst recognition = new SpeechRecognition()\n\nrecognition.continous = true\nrecognition.interimResults = true\nrecognition.lang = 'en-US'\n\n\nclass VoiceRecognition extends Component {\n\tconstructor(props) {\n    super(props)\n    \tthis.state = {\n     \t listening: false\n    }\n\t    this.toggleListen = this.toggleListen.bind(this)\n\t    this.handleListen = this.handleListen.bind(this)\n  \t}\n  \n  toggleListen() {\n    this.setState({\n      listening: !this.state.listening\n    }, this.handleListen)\n  }\n\n\thandleListen = () => {\n\t\tif (this.state.listening) recognition.start()\n\n\t    let finalTranscript = ''\n\t    recognition.onresult = event => {\n\t\t    let interimTranscript = ''\n\n\t\t    for (let i = event.resultIndex; i < event.results.length; i++) {\n\t\t    \tconst transcript = event.results[i][0].transcript;\n\t\t        if (event.results[i].isFinal) finalTranscript += transcript + ' ';\n\t\t        else interimTranscript += transcript;\n\t\t    }\n\t\t    if(document.getElementById('description')) {\n\t\t    \tconsole.log(document.getElementById('description'))\n\t\t    \tdocument.getElementById('description').value = finalTranscript\n\t\t    \tthis.props.updateDescriptionInput(finalTranscript)\n\t\t    }\n\t\t    else {\n\t\t    \tif(finalTranscript === 'no '){\n\t\t    \t\tconsole.log(document.getElementById('cancelEditTask'))\n\t\t    \t\tdocument.getElementById('cancelEditTask').click()\n\t\t    \t}\n\t\t    \tif(finalTranscript === 'yes '){\n\t\t    \t\tdocument.getElementById('submitEditTask').click()\n\t\t    \t}\n\t\t    }\n\t\t    \n\t\t}\n\t}\n\n\n\trender() {\n\t\treturn (\n\t\t\t<div style={container}>\n\t\t\t\t<img id = 'microphone-btn' \n\t\t\t\tclassName='pointer grow'\n\t\t\t\tsrc={mic} \n\t\t\t\twidth = \"50px\"\n\t\t\t\tonClick={this.toggleListen} \n\t\t\t\t/>\n     \t\t</div>\n\t\t)\n\t}\n}\n\n\nexport default VoiceRecognition;\n\nconst styles = {\n  container: {\n    display: 'flex',\n    flexDirection: 'column',\n    alignItems: 'center',\n    textAlign: 'center'\n  },\n\n}\n\nconst { container } = styles"]},"metadata":{},"sourceType":"module"}