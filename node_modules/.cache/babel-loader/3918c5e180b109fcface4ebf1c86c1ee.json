{"ast":null,"code":"import React from 'react';\nconst speechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\nconst recognition = new speechRecognition();\nrecognition.continous = true;\nrecognition.lang = 'en-US';\nrecognition.start();\n\nclass VoiceRecognition extends React.Component {\n  constructor() {\n    super();\n\n    this.toggleListen = () => {\n      this.setState({\n        listening: !this.state.listening\n      }, this.handleListen);\n    };\n\n    this.handleListen = () => {};\n\n    this.voiceCommands = () => {\n      console.log('hi there'); //On start\n\n      recognition.onstart = () => {\n        console.log('Voice is active');\n      }; // Do something with result\n\n\n      recognition.onresult = e => {\n        let current = e.rsultIndex;\n        let transcript = e.result[current][0].transcript;\n        console.log(transcript);\n      };\n    };\n\n    this.state = {\n      count: 0,\n      setCount: 0,\n      listening: false\n    };\n  }\n\n  componentDidMount() {\n    this.voiceCommands();\n  }\n\n  render() {\n    this.voiceCommands();\n    console.log('helli');\n    return 0;\n  }\n\n}\n\nexport default VoiceRecognition;","map":{"version":3,"sources":["/home/oz/Desktop/git/task-app-front/src/components/VoiceRecognition/VoiceRecognition.js"],"names":["React","speechRecognition","window","webkitSpeechRecognition","recognition","continous","lang","start","VoiceRecognition","Component","constructor","toggleListen","setState","listening","state","handleListen","voiceCommands","console","log","onstart","onresult","e","current","rsultIndex","transcript","result","count","setCount","componentDidMount","render"],"mappings":"AAAA,OAAOA,KAAP,MAAkB,OAAlB;AAEA,MAAMC,iBAAiB,GAAGC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBAA7D;AAEA,MAAMC,WAAW,GAAG,IAAIH,iBAAJ,EAApB;AAEAG,WAAW,CAACC,SAAZ,GAAwB,IAAxB;AACAD,WAAW,CAACE,IAAZ,GAAmB,OAAnB;AACAF,WAAW,CAACG,KAAZ;;AAEA,MAAMC,gBAAN,SAA+BR,KAAK,CAACS,SAArC,CAA+C;AAC9CC,EAAAA,WAAW,GAAG;AACb;;AADa,SASdC,YATc,GASC,MAAM;AACpB,WAAKC,QAAL,CAAc;AAACC,QAAAA,SAAS,EAAE,CAAC,KAAKC,KAAL,CAAWD;AAAxB,OAAd,EAAkD,KAAKE,YAAvD;AACA,KAXa;;AAAA,SAadA,YAbc,GAaC,MAAM,CAEpB,CAfa;;AAAA,SAsBdC,aAtBc,GAsBE,MAAM;AACrBC,MAAAA,OAAO,CAACC,GAAR,CAAY,UAAZ,EADqB,CAErB;;AACAd,MAAAA,WAAW,CAACe,OAAZ,GAAsB,MAAM;AAC3BF,QAAAA,OAAO,CAACC,GAAR,CAAY,iBAAZ;AACA,OAFD,CAHqB,CAOrB;;;AACAd,MAAAA,WAAW,CAACgB,QAAZ,GAAwBC,CAAD,IAAO;AAC7B,YAAIC,OAAO,GAAGD,CAAC,CAACE,UAAhB;AAEA,YAAIC,UAAU,GAAGH,CAAC,CAACI,MAAF,CAASH,OAAT,EAAkB,CAAlB,EAAqBE,UAAtC;AACAP,QAAAA,OAAO,CAACC,GAAR,CAAYM,UAAZ;AACA,OALD;AAMA,KApCa;;AAEb,SAAKV,KAAL,GAAa;AACZY,MAAAA,KAAK,EAAE,CADK;AAEZC,MAAAA,QAAQ,EAAE,CAFE;AAGZd,MAAAA,SAAS,EAAE;AAHC,KAAb;AAKA;;AAUDe,EAAAA,iBAAiB,GAAG;AACnB,SAAKZ,aAAL;AACA;;AAmBDa,EAAAA,MAAM,GAAG;AACR,SAAKb,aAAL;AACAC,IAAAA,OAAO,CAACC,GAAR,CAAY,OAAZ;AACA,WAAO,CAAP;AACA;;AA3C6C;;AA+C/C,eAAeV,gBAAf","sourcesContent":["import React from 'react'\n\nconst speechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\n\nconst recognition = new speechRecognition();\n\nrecognition.continous = true\nrecognition.lang = 'en-US'\nrecognition.start()\n\nclass VoiceRecognition extends React.Component {\n\tconstructor() {\n\t\tsuper();\n\t\tthis.state = {\n\t\t\tcount: 0,\n\t\t\tsetCount: 0,\n\t\t\tlistening: false\n\t\t}\t\n\t}\n\t\n\ttoggleListen = () => {\n\t\tthis.setState({listening: !this.state.listening}, this.handleListen)\n\t}\n\n\thandleListen = () => {\n\n\t}\n\n\tcomponentDidMount() {\n\t\tthis.voiceCommands();\n\t}\n\n\n\tvoiceCommands = () => {\n\t\tconsole.log('hi there')\n\t\t//On start\n\t\trecognition.onstart = () => {\n\t\t\tconsole.log('Voice is active')\n\t\t}\n\n\t\t// Do something with result\n\t\trecognition.onresult = (e) => {\n\t\t\tlet current = e.rsultIndex\n\n\t\t\tlet transcript = e.result[current][0].transcript\n\t\t\tconsole.log(transcript)\n\t\t}\n\t}\n\n\trender() {\n\t\tthis.voiceCommands();\n\t\tconsole.log('helli')\n\t\treturn 0\n\t}\n}\n\n\nexport default VoiceRecognition;\n\n\n\t"]},"metadata":{},"sourceType":"module"}