{"ast":null,"code":"import React, { useState, useEffect } from 'react';\nconst speechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\nconst recognition = new speechRecognition();\nrecognition.start();\n\nclass VoiceRecognition extends React.Component {\n  constructor() {\n    super();\n\n    this.voiceCommands = () => {\n      console.log('hi there'); //On start\n\n      recognition.onstart = () => {\n        console.log('Voice is active');\n      }; // Do something with result\n\n\n      recognition.onresult = e => {\n        let current = e.rsultIndex;\n        let transcript = e.result[current][0].transcript;\n        console.log(transcript);\n      };\n    };\n\n    this.state = {\n      count: 0,\n      setCount: 0\n    };\n  }\n\n  componentDidMount() {\n    this.voiceCommands();\n  }\n\n  render() {\n    console.log('helli');\n    return 0;\n  }\n\n}\n\nexport default VoiceRecognition;","map":{"version":3,"sources":["/home/oz/Desktop/git/task-app-front/src/components/VoiceRecognition/VoiceRecognition.js"],"names":["React","useState","useEffect","speechRecognition","window","webkitSpeechRecognition","recognition","start","VoiceRecognition","Component","constructor","voiceCommands","console","log","onstart","onresult","e","current","rsultIndex","transcript","result","state","count","setCount","componentDidMount","render"],"mappings":"AAAA,OAAOA,KAAP,IAAeC,QAAf,EAAyBC,SAAzB,QAA0C,OAA1C;AAEA,MAAMC,iBAAiB,GAAGC,MAAM,CAACD,iBAAP,IAA4BC,MAAM,CAACC,uBAA7D;AAEA,MAAMC,WAAW,GAAG,IAAIH,iBAAJ,EAApB;AAEAG,WAAW,CAACC,KAAZ;;AAEA,MAAMC,gBAAN,SAA+BR,KAAK,CAACS,SAArC,CAA+C;AAC9CC,EAAAA,WAAW,GAAG;AACb;;AADa,SAadC,aAbc,GAaE,MAAM;AACrBC,MAAAA,OAAO,CAACC,GAAR,CAAY,UAAZ,EADqB,CAErB;;AACAP,MAAAA,WAAW,CAACQ,OAAZ,GAAsB,MAAM;AAC3BF,QAAAA,OAAO,CAACC,GAAR,CAAY,iBAAZ;AACA,OAFD,CAHqB,CAOrB;;;AACAP,MAAAA,WAAW,CAACS,QAAZ,GAAwBC,CAAD,IAAO;AAC7B,YAAIC,OAAO,GAAGD,CAAC,CAACE,UAAhB;AAEA,YAAIC,UAAU,GAAGH,CAAC,CAACI,MAAF,CAASH,OAAT,EAAkB,CAAlB,EAAqBE,UAAtC;AACAP,QAAAA,OAAO,CAACC,GAAR,CAAYM,UAAZ;AACA,OALD;AAMA,KA3Ba;;AAEb,SAAKE,KAAL,GAAa;AACZC,MAAAA,KAAK,EAAE,CADK;AAEZC,MAAAA,QAAQ,EAAE;AAFE,KAAb;AAIA;;AAEDC,EAAAA,iBAAiB,GAAG;AACnB,SAAKb,aAAL;AACA;;AAmBDc,EAAAA,MAAM,GAAG;AACRb,IAAAA,OAAO,CAACC,GAAR,CAAY,OAAZ;AACA,WAAO,CAAP;AACA;;AAjC6C;;AAqC/C,eAAeL,gBAAf","sourcesContent":["import React, {useState, useEffect } from 'react'\n\nconst speechRecognition = window.speechRecognition || window.webkitSpeechRecognition;\n\nconst recognition = new speechRecognition();\n\nrecognition.start()\n\nclass VoiceRecognition extends React.Component {\n\tconstructor() {\n\t\tsuper();\n\t\tthis.state = {\n\t\t\tcount: 0,\n\t\t\tsetCount: 0\n\t\t}\t\n\t}\n\t\n\tcomponentDidMount() {\n\t\tthis.voiceCommands();\n\t}\n\n\n\tvoiceCommands = () => {\n\t\tconsole.log('hi there')\n\t\t//On start\n\t\trecognition.onstart = () => {\n\t\t\tconsole.log('Voice is active')\n\t\t}\n\n\t\t// Do something with result\n\t\trecognition.onresult = (e) => {\n\t\t\tlet current = e.rsultIndex\n\n\t\t\tlet transcript = e.result[current][0].transcript\n\t\t\tconsole.log(transcript)\n\t\t}\n\t}\n\n\trender() {\n\t\tconsole.log('helli')\n\t\treturn 0\n\t}\n}\n\n\nexport default VoiceRecognition;\n\n\n\t"]},"metadata":{},"sourceType":"module"}